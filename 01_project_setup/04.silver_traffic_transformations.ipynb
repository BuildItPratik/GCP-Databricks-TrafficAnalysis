{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9622b2e7-41f3-4332-9236-dd1f60625cfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2df2d82-6756-403a-890d-1f3c63002abf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./commons\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca1e08f-ce1d-4d8d-872a-10356c237d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reading from bronze table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92afc789-ce44-40a3-99cd-cd3a667500f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_BronzeTrafficTable(environment):\n",
    "    print('Reading the Bronze Table Data : ',end='')\n",
    "    df_bronzeTraffic = (spark.readStream.table(f\"`{environment}_catalog`.`bronze`.raw_traffic\"))\n",
    "    print(f'Reading {environment}_catalog.bronze.raw_traffic Success!')\n",
    "    return df_bronzeTraffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69a7783d-9882-4d13-acc7-e1221ca4448f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## quality check 1: Handing duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bea0e05-ee2b-4468-b35f-665d7445c03c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## quality check 2: Handling NULL values by replacing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fccb4f-397c-4e4d-b1cd-74899bc4039c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Getting count of Electric vehicles by creating new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c3694c-c784-401d-bd2f-1ff608a43743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ev_Count(df):\n",
    "    print('Creating Electric Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_ev = df.withColumn('Electric_Vehicles_Count', col('EV_Car') + col('EV_Bike'))\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa1cfa9-4033-43da-9e8a-4742768e687e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating columns to get Count of all motor vehicles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d9c9b9c-4ae2-4f73-92df-eabb60ad3fd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Motor_Count(df):\n",
    "    print('Creating All Motor Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_motor = df.withColumn('Motor_Vehicles_Count',\n",
    "                            col('Electric_Vehicles_Count') + col('Two_wheeled_motor_vehicles') + col('Cars_and_taxis') + col('Buses_and_coaches') + col('LGV_Type') + col('HGV_Type')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405a7f72-45f5-4546-882b-d576adf7e2a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Transformed Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e19f1de-99dc-480c-8d01-35fd60a0ca75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_TransformedTime(df):\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print('Creating Transformed Time column : ',end='')\n",
    "    df_timestamp = df.withColumn('Transformed_Time', current_timestamp())\n",
    "    print('Success!!')\n",
    "    return df_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db12b66a-2daf-42e4-8a4b-72da8cc05e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Writing the Transformed data to Silver_Traffic Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36db0c57-d26a-4b01-8e32-b536071352a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_SilverTable(StreamingDF,environment):\n",
    "    print('Writing the silver_traffic Data : ',end='') \n",
    "\n",
    "    write_StreamSilver = (StreamingDF.writeStream\n",
    "                .format('delta')\n",
    "                .option('checkpointLocation',checkpoint+ \"/SilverTrafficLoad/Checkpt/\")\n",
    "                .outputMode('append')\n",
    "                .queryName(\"SilverTrafficWriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}_catalog`.`silver`.`silver_traffic`\"))\n",
    "    \n",
    "    write_StreamSilver.awaitTermination()\n",
    "    print(f'Writing `{environment}_catalog`.`silver`.`silver_traffic` Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5938c1e-c100-4b8d-8174-6b538876e635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09096fc1-ba20-4a28-a954-e07a81443b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Reading the bronze traffic data\n",
    "df_trafficdata = read_BronzeTrafficTable(env)\n",
    "\n",
    "# To remove duplicate rows\n",
    "df_dups = remove_Dups(df_trafficdata)\n",
    "\n",
    "# To raplce any NULL values\n",
    "Allcolumns =df_dups.schema.names\n",
    "df_nulls = handle_NULLs(df_dups,Allcolumns)\n",
    "\n",
    "## To get the total EV_Count\n",
    "df_ev = ev_Count(df_nulls)\n",
    "\n",
    "## To get the Total Motor vehicle count\n",
    "df_motor = Motor_Count(df_ev)\n",
    "\n",
    "## Calling Transformed time function\n",
    "df_final = create_TransformedTime(df_motor)\n",
    "\n",
    "## Writing to silver_traffic\n",
    "write_Traffic_SilverTable(df_final, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eb5c685-2190-437c-ae72-66c9ffcf0d3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT Count(*) FROM `{env}_catalog`.`silver`.`silver_traffic` LIMIT 10\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04.silver_traffic_transformations",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "5d7188cb-d3ee-4dad-8fb1-542b5a481155",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
